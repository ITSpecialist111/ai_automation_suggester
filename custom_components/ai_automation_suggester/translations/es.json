{
  "title": "Sugeridor de Automatizaciones con IA",
  "config": {
    "step": {
      "user": {
        "title": "Seleccionar Proveedor de IA",
        "data": {
          "provider": "Proveedor de IA"
        }
      },
      "openai": {
        "title": "Configurar OpenAI",
        "data": {
          "openai_api_key": "Clave API de OpenAI",
          "openai_model": "Modelo OpenAI",
          "openai_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "anthropic": {
        "title": "Configurar Anthropic",
        "data": {
          "anthropic_api_key": "Clave API de Anthropic",
          "anthropic_model": "Modelo Anthropic",
          "anthropic_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "google": {
        "title": "Configurar Google",
        "data": {
          "google_api_key": "Clave API de Google",
          "google_model": "Modelo Google",
          "google_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "groq": {
        "title": "Configurar Groq",
        "data": {
          "groq_api_key": "Clave API de Groq",
          "groq_model": "Modelo Groq",
          "groq_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "localai": {
        "title": "Configurar LocalAI",
        "data": {
          "localai_ip": "Dirección IP de LocalAI",
          "localai_port": "Puerto de LocalAI",
          "localai_https": "Usar HTTPS para LocalAI",
          "localai_model": "Modelo LocalAI",
          "localai_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "ollama": {
        "title": "Configurar Ollama",
        "data": {
          "ollama_ip": "Dirección IP de Ollama",
          "ollama_port": "Puerto de Ollama",
          "ollama_https": "Usar HTTPS para Ollama",
          "ollama_model": "Modelo Ollama",
          "ollama_temperature": "Temperatura",
          "ollama_disable_think": "Desactivar Modo Pensamiento (Ollama)",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "custom_openai": {
        "title": "Configurar OpenAI Personalizado",
        "data": {
          "custom_openai_endpoint": "Endpoint OpenAI Personalizado",
          "custom_openai_api_key": "Clave API OpenAI Personalizada (Opcional)",
          "custom_openai_model": "Modelo OpenAI Personalizado",
          "custom_openai_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "mistral": {
        "title": "Configurar Mistral AI",
        "data": {
          "mistral_api_key": "Clave API de Mistral",
          "mistral_model": "Modelo Mistral",
          "mistral_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "perplexity": {
        "title": "Configurar Perplexity AI",
        "data": {
          "perplexity_api_key": "Clave API de Perplexity",
          "perplexity_model": "Modelo Perplexity",
          "perplexity_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "openrouter": {
        "title": "Configurar OpenRouter",
        "data": {
          "openrouter_api_key": "Clave API de OpenRouter",
          "openrouter_model": "Modelo OpenRouter",
          "openrouter_reasoning_max_tokens": "Máx Tokens de Razonamiento OpenRouter",
          "openrouter_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      },
      "openai_azure": {
        "title": "Configurar OpenAI Azure",
        "data": {
          "openai_azure_api_key": "Clave API de Azure OpenAI",
          "openai_azure_deployment_id": "ID de Despliegue de Azure",
          "openai_azure_endpoint": "Endpoint de Azure",
          "openai_azure_api_version": "Versión API de Azure",
          "openai_azure_temperature": "Temperatura",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        }
      }
    },
    "error": {
      "api_error": "Falló la validación de la API: {error_message}",
      "cannot_connect": "No se pudo conectar. Por favor, revisa tu configuración y red.",
      "unknown": "Ocurrió un error desconocido. Por favor, revisa los logs para más detalles."
    },
    "abort": {
      "already_configured": "Este proveedor de IA ya está configurado. Puedes editarlo desde la página de integraciones."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Opciones del Sugeridor de Automatizaciones con IA",
        "data": {
          "openai_api_key": "Clave API de OpenAI",
          "openai_model": "Modelo OpenAI",
          "openai_temperature": "Temperatura (OpenAI)",
          "anthropic_api_key": "Clave API de Anthropic",
          "anthropic_model": "Modelo Anthropic",
          "anthropic_temperature": "Temperatura (Anthropic)",
          "google_api_key": "Clave API de Google",
          "google_model": "Modelo Google",
          "google_temperature": "Temperatura (Google)",
          "groq_api_key": "Clave API de Groq",
          "groq_model": "Modelo Groq",
          "groq_temperature": "Temperatura (Groq)",
          "localai_ip": "Dirección IP de LocalAI",
          "localai_port": "Puerto de LocalAI",
          "localai_https": "Usar HTTPS para LocalAI",
          "localai_model": "Modelo LocalAI",
          "localai_temperature": "Temperatura (LocalAI)",
          "ollama_ip": "Dirección IP de Ollama",
          "ollama_port": "Puerto de Ollama",
          "ollama_https": "Usar HTTPS para Ollama",
          "ollama_model": "Modelo Ollama",
          "ollama_temperature": "Temperatura (Ollama)",
          "ollama_disable_think": "Desactivar Modo Pensamiento (Ollama)",
          "custom_openai_endpoint": "Endpoint OpenAI Personalizado",
          "custom_openai_api_key": "Clave API OpenAI Personalizada",
          "custom_openai_model": "Modelo OpenAI Personalizado",
          "custom_openai_temperature": "Temperatura (OpenAI Personalizado)",
          "mistral_api_key": "Clave API de Mistral",
          "mistral_model": "Modelo Mistral",
          "mistral_temperature": "Temperatura (Mistral AI)",
          "perplexity_api_key": "Clave API de Perplexity",
          "perplexity_model": "Modelo Perplexity",
          "perplexity_temperature": "Temperatura (Perplexity AI)",
          "openrouter_api_key": "Clave API de OpenRouter",
          "openrouter_model": "Modelo OpenRouter",
          "openrouter_reasoning_max_tokens": "Máx Tokens de Razonamiento OpenRouter",
          "openrouter_temperature": "Temperatura (OpenRouter)",
          "openai_azure_api_key": "Clave API de Azure OpenAI",
          "openai_azure_deployment_id": "ID de Despliegue de Azure",
          "openai_azure_endpoint": "Endpoint de Azure",
          "openai_azure_api_version": "Versión API de Azure",
          "openai_azure_temperature": "Temperatura (OpenAI Azure)",
          "max_input_tokens": "Máx Tokens de Entrada",
          "max_output_tokens": "Máx Tokens de Salida"
        },
        "description": "Ajusta la configuración para tus proveedores de IA. Se usarán los campos relevantes para tu proveedor configurado. Configuraciones comunes como los límites de tokens se configuran por proveedor."
      }
    },
    "error": {
        "invalid_input": "Uno o más valores son inválidos."
    }
  },
  "services": {
    "generate_suggestions": {
      "name": "Generar Sugerencias",
      "description": "Activar manualmente las sugerencias de automatización con IA.",
      "fields": {
        "provider_config": {
          "name": "Configuración del Proveedor",
          "description": "¿Qué configuración de proveedor usar (si tienes varias)?"
        },
        "custom_prompt": {
          "name": "Prompt Personalizado",
          "description": "Prompt personalizado opcional para anular el prompt del sistema predeterminado o guiar las sugerencias hacia temas específicos"
        },
        "all_entities": {
          "name": "Considerar Todas las Entidades",
          "description": "Si es verdadero, considerar todas las entidades en lugar de solo las nuevas entidades."
        },
        "domains": {
          "name": "Dominios",
          "description": "Lista de dominios a considerar. Si está vacío, considerar todos los dominios."
        },
        "entity_limit": {
          "name": "Límite de Entidades",
          "description": "Número máximo de entidades a considerar (seleccionadas aleatoriamente)."
        },
        "automation_read_yaml": {
          "name": "Leer archivo 'automations.yaml'",
          "description": "Lee y añade el código yaml de las automatizaciones encontradas en el archivo automations.yaml. Esta acción usará muchos tokens de entrada, úsala con cuidado y con modelos con una ventana de entrada grande (ej. Gemini)."
        }
      }
    }
  }
}
